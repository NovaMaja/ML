{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textanalytics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NovaMaja/ML/blob/master/textanalytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "z_p3sOv1wJVi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Text analysis example\n",
        "##predicitng tags from StackOverflow posts\n",
        "\n",
        "This notebook is based on the blogpost and sample code\n",
        "\"Intro to text classification with Keras\" by Sara Robinson, Josh Gordon, and Marianne Linhares Monteiro : https://cloud.google.com/blog/products/gcp/intro-to-text-classification-with-keras-automatically-tagging-stack-overflow-posts"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "frTMl3sShA3P",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "783h64rGhA3T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# This code was tested with TensorFlow v1.4\n",
        "print(\"You have TensorFlow version\", tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "c7te21f7hA3V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The CSV was generated from this query: https://bigquery.cloud.google.com/savedquery/513927984416:c494494324be4a80b1fc55f613abb39c\n",
        "# The data is also publicly available at this Cloud Storage URL: https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv\n",
        "data = pd.read_csv(\"stack-overflow-data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "chAbp3ryhA3X",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UYmXmZXFm0zc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Confirm that we have a balanced dataset\n",
        "# Note: data was randomly shuffled in our BigQuery query\n",
        "data['tags'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "h_SDal0khA3n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split data into train and test\n",
        "train_size = int(len(data) * .8)\n",
        "print (\"Train size: %d\" % train_size)\n",
        "print (\"Test size: %d\" % (len(data) - train_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "anD38iilhA3r",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_posts = data['post'][:train_size]\n",
        "train_tags = data['tags'][:train_size]\n",
        "\n",
        "test_posts = data['post'][train_size:]\n",
        "test_tags = data['tags'][train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZdvY7o4Xrubk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Tokenizer\n",
        "Keras has some built in methods for preprocessing text. The Tokenizer class provides methods to count the unique words in our vocabulary and assign each of those words to indices. We need this to create the training and test data for our model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z4GblctFhA3u",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_words = 1000\n",
        "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YatMLCKXhA3x",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenize.fit_on_texts(train_posts) # only fit on train\n",
        "x_train = tokenize.texts_to_matrix(train_posts)\n",
        "x_test = tokenize.texts_to_matrix(test_posts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iGdJwHe-t19D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next we need to convert our labels into integer indicies "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8quTsErLhA3z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use sklearn utility to convert label strings to numbered index\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_tags)\n",
        "y_train = encoder.transform(train_tags)\n",
        "y_test = encoder.transform(test_tags)\n",
        "num_classes = np.max(y_train) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XZFsdLYVhA33",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Inspect the dimenstions of our training and test data (this is helpful to debug)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cBIkzTOZhA36",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This model trains very quickly and 2 epochs are already more than enough\n",
        "# Training for more epochs will likely lead to overfitting on this dataset\n",
        "# You can try tweaking these hyperparamaters when using this model with your own data\n",
        "batch_size = 32\n",
        "epochs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XdrFuwx4hA39",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build the model (fill in the blanks!)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    #fill in one dense layer with 512, activation = 'relu', input_shape = (max_words,)\n",
        "    \n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    #fill in one dense layer with num_classes, activation = 'softmax'\n",
        "\n",
        "  ])\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rzi-9GaBhA4A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model.fit trains the model\n",
        "# The validation_split param tells Keras what % of our training data should be used in the validation set\n",
        "# You can see the validation loss decreasing slowly when you run this\n",
        "# Because val_loss is no longer decreasing we stop training to prevent overfitting\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zjwBD8qFhA4D",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluate the accuracy of our trained model\n",
        "score = model.evaluate(x_test, y_test,\n",
        "                       batch_size=batch_size, verbose=1)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "f000lYoxhA4F",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Here's how to generate a prediction on individual examples\n",
        "text_labels = encoder.classes_ \n",
        "\n",
        "for i in range(10):\n",
        "    prediction = model.predict(np.array([x_test[i]]))\n",
        "    predicted_label = text_labels[np.argmax(prediction)]\n",
        "    print(test_posts.iloc[i][:50], \"...\")\n",
        "    print('Actual label:' + test_tags.iloc[i])\n",
        "    print(\"Predicted label: \" + predicted_label + \"\\n\")  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HKUgUHLAhA4I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_softmax = model.predict(x_test)\n",
        "\n",
        "y_pred_1d = []\n",
        "\n",
        "for i in range(0, len(y_softmax)):\n",
        "    probs = y_softmax[i]\n",
        "    predicted_index = np.argmax(probs)\n",
        "    y_pred_1d.append(predicted_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rqqIG5KnhA4K",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This utility function is from the sklearn docs: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize=30)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, fontsize=22)\n",
        "    plt.yticks(tick_marks, classes, fontsize=22)\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label', fontsize=25)\n",
        "    plt.xlabel('Predicted label', fontsize=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8nWz6EFqhA4L",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnf_matrix = confusion_matrix(y_test, y_pred_1d)\n",
        "plt.figure(figsize=(24,20))\n",
        "plot_confusion_matrix(cnf_matrix, classes=text_labels, title=\"Confusion matrix\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tc8AyEfim03v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}