{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NovaMaja/ML/blob/master/spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Yn-0DIDU_8a_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Intro to Apache spark with Python\n",
        "This tutorial assumes you are working in Google Colab. If you are working on a local computer the installation procedure may be different.\n",
        "\n",
        "First we need to install spark and java on the google computer we are conneted to. If the code below does not work got to the [spark repository](http://apache.osuosl.org/spark/) and look for a current version, then change the url below to match with it. \n",
        "\n",
        "This Notebook is largly based on a [blog post by Asif Ahmed](https://towardsdatascience.com/pyspark-in-google-colab-6821c2faf41c)"
      ]
    },
    {
      "metadata": {
        "id": "FKnmGB_E_UTm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0M3v6X65A40z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to tell colab where to find the libraries we installed"
      ]
    },
    {
      "metadata": {
        "id": "4xgsvyPR_hKe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PsJ3OabRBIAa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we can start Spark:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S0wJNRbbCwte",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sALNdqF7DZPe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Linear regression example\n",
        "We will use pyspark for linear regression on the Boston Housing dataset."
      ]
    },
    {
      "metadata": {
        "id": "ZeYHkQP_Dztg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}